---
title: "Coding period week 1"
excerpt: ""

sidebar:
  nav: "docs"

toc: true
toc_label: "TOC installation"
toc_icon: "cog"


categories:
- GSoC
tags:
- Jderobot

author: Diego Charrez
pinned: false
---

I spent the community bonding period learning more about Jderobot's Behavior Studio which focuses on using deep learning for self driving cars. It was also great to talk to my mentors and meet other members from Behavior Studio, they are all very kind and supportive. and know more about the Jderobot community.

The first week of the coding period, I started by studying the tensorflow agents library which has a set of great tutorials, and implemented some basic examples with Deep Q-Networks (DQN), Additionally I set up a Dockerfile to ease my work.

Additionaly I set the environment where I will be working using a GPU,

Exploring tensorflow agents and DQN in an easier environment like cartpole, would help me translate the implementation to more complex environment like Formula 1 environment.

![Cartpole]({{ "/assets/images/blogs/cartpole.gif" | absolute_url }})

# What I have learned

## Deep Q-Networks?

Deep Q-Networks were developed by Deepmind in 2015, combining deep neural networks and Q-learning which is a classic Reinforcement learning algorithm. Q-learning uses the state-value function Q that measures how good is to take an action $a$ from the state $s$ and it is denoted as $Q_{\pi}(s,a)$ \[[1]\](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf).

$$\begin{equation}Q^{*}(s, a) = \mathbb{E}\left[ r + \gamma \max_{a'} Q^{*}(s', a') \right]\end{equation}$$

## DQN on Cartpole




# Implemented

# References

[1] Deepmind, [DQN (Deep Q-Network) algorithm](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf), 2015.
[2] Sergio Guadarrama et at, [TF-Agents A library for Reinforcement Learning in TensorFlow](), 2018.